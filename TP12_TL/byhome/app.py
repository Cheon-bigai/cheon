import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import cv2
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.models as models
from PIL import Image
import io
import os
import glob

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë° ìƒ‰ìƒ ë³µì› ë„êµ¬",
    page_icon="ğŸ”",
    layout="wide"
)

# ë””ë°”ì´ìŠ¤ ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ì´ë¯¸ì§€ í¬ê¸° ì„¤ì •
IMG_HEIGHT = 256
IMG_WIDTH = 256

# U-Net with ResNet50 ëª¨ë¸ ì •ì˜
class UNetWithResNet50Encoder(nn.Module):
    def __init__(self, n_classes=1):
        super(UNetWithResNet50Encoder, self).__init__()
        
        # ResNet50ì„ ì¸ì½”ë”ë¡œ ì‚¬ìš©
        resnet = models.resnet50(pretrained=True)
        
        # ResNet50ì˜ ê³„ì¸µë“¤ì„ ì¸ì½”ë”ë¡œ ì‚¬ìš©
        self.encoder1 = nn.Sequential(
            resnet.conv1,
            resnet.bn1,
            resnet.relu
        )  # 64 ì±„ë„
        self.pool1 = resnet.maxpool
        self.encoder2 = resnet.layer1  # 256 ì±„ë„
        self.encoder3 = resnet.layer2  # 512 ì±„ë„
        self.encoder4 = resnet.layer3  # 1024 ì±„ë„
        self.encoder5 = resnet.layer4  # 2048 ì±„ë„
        
        # ë””ì½”ë” ì •ì˜
        self.decoder5 = self._decoder_block(2048, 1024)
        self.decoder4 = self._decoder_block(1024 + 1024, 512)
        self.decoder3 = self._decoder_block(512 + 512, 256)
        self.decoder2 = self._decoder_block(256 + 256, 64)
        self.decoder1 = self._decoder_block(64 + 64, 32)
        
        # ìµœì¢… ì¶œë ¥ ë ˆì´ì–´
        self.final_conv = nn.Conv2d(32, n_classes, kernel_size=1)
        self.final_activation = nn.Sigmoid()
        
    def _decoder_block(self, in_channels, out_channels):
        return nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )
    
    def forward(self, x):
        # ì¸ì½”ë” ë‹¨ê³„
        e1 = self.encoder1(x)
        p1 = self.pool1(e1)
        e2 = self.encoder2(p1)
        e3 = self.encoder3(e2)
        e4 = self.encoder4(e3)
        e5 = self.encoder5(e4)
        
        # ë””ì½”ë” ë‹¨ê³„ì™€ ìŠ¤í‚µ ì—°ê²°
        d5 = self.decoder5(e5)
        d5 = nn.functional.interpolate(d5, size=e4.size()[2:], mode='bilinear', align_corners=True)
        d5 = torch.cat([d5, e4], dim=1)
        
        d4 = self.decoder4(d5)
        d4 = nn.functional.interpolate(d4, size=e3.size()[2:], mode='bilinear', align_corners=True)
        d4 = torch.cat([d4, e3], dim=1)
        
        d3 = self.decoder3(d4)
        d3 = nn.functional.interpolate(d3, size=e2.size()[2:], mode='bilinear', align_corners=True)
        d3 = torch.cat([d3, e2], dim=1)
        
        d2 = self.decoder2(d3)
        d2 = nn.functional.interpolate(d2, size=e1.size()[2:], mode='bilinear', align_corners=True)
        d2 = torch.cat([d2, e1], dim=1)
        
        d1 = self.decoder1(d2)
        d1 = nn.functional.interpolate(d1, size=x.size()[2:], mode='bilinear', align_corners=True)
        
        out = self.final_conv(d1)
        out = self.final_activation(out)
        
        return out

# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_image(img):
    # RGB ì´ë¯¸ì§€ì¸ì§€ í™•ì¸
    if len(img.shape) == 2:
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
    elif img.shape[2] == 4:  # RGBA ì´ë¯¸ì§€ì¸ ê²½ìš°
        img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)
    
    # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
    img = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))
    
    # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥
    original_img = img.copy()
    
    # í‘ë°± ì´ë¯¸ì§€ ìƒì„±
    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    
    # ì „ì²˜ë¦¬ ë³€í™˜
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])
    
    # í…ì„œë¡œ ë³€í™˜
    tensor_img = transform(img)
    tensor_img = tensor_img.unsqueeze(0).to(device)
    
    return tensor_img, original_img, gray_img

# ì˜ˆì¸¡ ê²°ê³¼ ì²˜ë¦¬ í•¨ìˆ˜
def postprocess_prediction(output_tensor, original_img):
    # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
    output_np = output_tensor.squeeze().cpu().detach().numpy()
    
    # ì´ì§„í™” (0.5 ì„ê³„ê°’)
    binary_mask = (output_np > 0.5).astype(np.uint8) * 255
    
    # ë§ˆìŠ¤í¬ë¥¼ 3ì±„ë„ë¡œ í™•ì¥
    mask_colored = cv2.cvtColor(binary_mask, cv2.COLOR_GRAY2RGB)
    
    # ì›ë³¸ ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ ê²°í•© (ìƒ‰ìƒ ë³µì›ëœ ì´ë¯¸ì§€)
    # ë§ˆìŠ¤í¬ ì˜ì—­ë§Œ ì›ë³¸ ì´ë¯¸ì§€ ìƒ‰ìƒ ìœ ì§€, ë‚˜ë¨¸ì§€ëŠ” í‘ë°±ìœ¼ë¡œ
    gray_3ch = cv2.cvtColor(cv2.cvtColor(original_img, cv2.COLOR_RGB2GRAY), cv2.COLOR_GRAY2RGB)
    
    # ë§ˆìŠ¤í¬ë¥¼ ì´ìš©í•˜ì—¬ ìƒ‰ìƒ ë³µì› ì´ë¯¸ì§€ ìƒì„±
    mask_bool = (binary_mask > 0)
    mask_bool_3ch = np.stack([mask_bool, mask_bool, mask_bool], axis=2)
    
    restored_img = np.where(mask_bool_3ch, original_img, gray_3ch)
    
    return binary_mask, restored_img

# ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹œê°í™” í•¨ìˆ˜
def visualize_segmentation(img, mask, alpha=0.5):
    # ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ê°€ ê°™ì€ í¬ê¸°ì¸ì§€ í™•ì¸
    img = cv2.resize(img, (mask.shape[1], mask.shape[0]))
    
    # ë§ˆìŠ¤í¬ ì‹œê°í™”ë¥¼ ìœ„í•œ ìƒ‰ìƒ ì„¤ì • (ë¹¨ê°„ìƒ‰)
    mask_color = np.zeros_like(img)
    mask_color[mask > 0] = [255, 0, 0]  # BGR í˜•ì‹ì—ì„œ ë¹¨ê°„ìƒ‰
    
    # ì´ë¯¸ì§€ì™€ ë§ˆìŠ¤í¬ í•©ì„±
    return cv2.addWeighted(img, 1, mask_color, alpha, 0)

# ë©”íŠ¸ë¦­ ê³„ì‚° í•¨ìˆ˜
def calculate_metrics(true_mask, pred_mask):
    # ì´ì§„í™”
    true_mask = (true_mask > 128).astype(np.uint8)
    pred_mask = (pred_mask > 128).astype(np.uint8)
    
    # IoU (Intersection over Union) ê³„ì‚°
    intersection = np.logical_and(true_mask, pred_mask).sum()
    union = np.logical_or(true_mask, pred_mask).sum()
    iou = intersection / union if union > 0 else 0
    
    # ì •ë°€ë„ (Precision) ê³„ì‚°
    tp = intersection
    fp = pred_mask.sum() - tp
    precision = tp / (tp + fp) if (tp + fp) > 0 else 0
    
    # ì¬í˜„ìœ¨ (Recall) ê³„ì‚°
    tp = intersection
    fn = true_mask.sum() - tp
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    
    # F1 ì ìˆ˜ ê³„ì‚°
    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0
    
    return {
        "IoU": iou,
        "Precision": precision,
        "Recall": recall,
        "F1 Score": f1
    }

# ë©”íŠ¸ë¦­ ì‹œê°í™” í•¨ìˆ˜
def visualize_metrics(metrics):
    fig, ax = plt.subplots(figsize=(10, 5))
    
    # ë©”íŠ¸ë¦­ ì´ë¦„ê³¼ ê°’
    names = list(metrics.keys())
    values = list(metrics.values())
    
    # ìˆ˜í‰ ë°” ì°¨íŠ¸ ìƒì„±
    bars = ax.barh(names, values, color=['#3498db', '#2ecc71', '#e74c3c', '#f39c12'])
    
    # ë°” ìœ„ì— ê°’ í‘œì‹œ
    for i, v in enumerate(values):
        ax.text(v + 0.01, i, f"{v:.4f}", va='center')
    
    # ì°¨íŠ¸ ì„¤ì •
    ax.set_xlim(0, 1.1)
    ax.set_xlabel('Score')
    ax.set_title('Segmentation Metrics')
    ax.grid(axis='x', linestyle='--', alpha=0.7)
    
    return fig

# ìƒ˜í”Œ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ì¶”ê°€ (ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì • í•„ìš”)
def get_sample_images(base_dir):
    sample_data = []
    
    # ê²½ë¡œ ì§€ì • (ì‹¤ì œ ë””ë ‰í† ë¦¬ êµ¬ì¡°ì— ë§ê²Œ ìˆ˜ì •)
    input_dir = os.path.join(base_dir, r"C:\Users\KDT-13\Desktop\KDT7\0.Project\TP12_TL\data\train_input")
    
    # ì´ë¯¸ì§€ íŒŒì¼ ê²€ìƒ‰
    if os.path.exists(input_dir):
        image_files = glob.glob(os.path.join(input_dir, "*.jpg")) + glob.glob(os.path.join(input_dir, "*.png"))
        
        # ìµœëŒ€ 10ê°œ ìƒ˜í”Œë§Œ ê°€ì ¸ì˜¤ê¸°
        for i, img_path in enumerate(image_files[:10]):
            sample_name = os.path.basename(img_path)
            sample_data.append({
                "id": i,
                "name": f"ìƒ˜í”Œ ì´ë¯¸ì§€ {i+1}: {sample_name}",
                "input_path": img_path,
                # GT ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ì • (ì‹¤ì œ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •)
                "gt_path": img_path.replace("input_images", "gt_images")
            })
    else:
        # ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ë”ë¯¸ ë°ì´í„° ìƒì„±
        for i in range(5):
            sample_data.append({
                "id": i,
                "name": f"ìƒ˜í”Œ ì´ë¯¸ì§€ {i+1}",
                "input_path": None,
                "gt_path": None
            })
    
    return sample_data

# ìƒ˜í”Œ ì´ë¯¸ì§€ ë¡œë“œ
def load_sample_image(sample):
    if sample["input_path"] and os.path.exists(sample["input_path"]):
        # ì‹¤ì œ ì´ë¯¸ì§€ ë¡œë“œ
        color_img = cv2.imread(sample["input_path"])
        color_img = cv2.cvtColor(color_img, cv2.COLOR_BGR2RGB)
        
        # GT ë§ˆìŠ¤í¬ ë¡œë“œ (ìˆëŠ” ê²½ìš°)
        if sample["gt_path"] and os.path.exists(sample["gt_path"]):
            true_mask = cv2.imread(sample["gt_path"], cv2.IMREAD_GRAYSCALE)
        else:
            # GT ë§ˆìŠ¤í¬ê°€ ì—†ìœ¼ë©´ ë”ë¯¸ ë§ˆìŠ¤í¬ ìƒì„±
            true_mask = np.zeros((IMG_HEIGHT, IMG_WIDTH), dtype=np.uint8)
            center_x, center_y = IMG_WIDTH // 2, IMG_HEIGHT // 2
            radius = min(IMG_WIDTH, IMG_HEIGHT) // 3
            cv2.circle(true_mask, (center_x, center_y), radius, 255, -1)
    else:
        # ì´ë¯¸ì§€ê°€ ì—†ìœ¼ë©´ ë”ë¯¸ ì´ë¯¸ì§€ ìƒì„±
        color_img = np.zeros((IMG_HEIGHT, IMG_WIDTH, 3), dtype=np.uint8)
        color_img[:, :, 0] = np.random.randint(0, 255)
        color_img[:, :, 1] = np.random.randint(0, 255)
        color_img[:, :, 2] = np.random.randint(0, 255)
        
        # ë”ë¯¸ ë§ˆìŠ¤í¬ ìƒì„±
        true_mask = np.zeros((IMG_HEIGHT, IMG_WIDTH), dtype=np.uint8)
        center_x, center_y = IMG_WIDTH // 2, IMG_HEIGHT // 2
        radius = min(IMG_WIDTH, IMG_HEIGHT) // 3
        cv2.circle(true_mask, (center_x, center_y), radius, 255, -1)
    
    return color_img, true_mask

# ëª¨ë¸ ë¡œë“œ í•¨ìˆ˜
@st.cache_resource
def load_model(model_path=None):
    model = UNetWithResNet50Encoder().to(device)
    
    try:
        if model_path and os.path.exists(model_path):
            # ì €ì¥ëœ ëª¨ë¸ íŒŒì¼ ë¡œë“œ
            checkpoint = torch.load(model_path, map_location=device)
            
            # ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
            if 'model_state_dict' in checkpoint:
                model.load_state_dict(checkpoint['model_state_dict'])
                print("ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤!")
            else:
                model.load_state_dict(checkpoint)
                print("ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤!")
        else:
            print("ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì´ˆê¸°í™”ëœ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    except Exception as e:
        print(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        st.error(f"ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    model.eval()
    return model

# ë©”ì¸ Streamlit ì•±
def main():
    st.title("ğŸ–¼ï¸ ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë° ìƒ‰ìƒ ë³µì› ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜")
    st.markdown("---")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    st.sidebar.title("ì„¤ì •")
    
    # ê¸°ë³¸ ë””ë ‰í† ë¦¬ ì„¤ì •
    base_dir = st.sidebar.text_input(
        "ê¸°ë³¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ",
        value="C:/Users/KDT-13/Desktop/KDT7/0.Project/TP12_TL"
    )
    
    # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
    model_path = st.sidebar.text_input(
        "ëª¨ë¸ íŒŒì¼ ê²½ë¡œ",
        value=os.path.join(base_dir, r"C:\Users\KDT-13\Desktop\KDT7\0.Project\TP12_TL\byhome\best_model.pth")
    )
    
    # ëª¨ë¸ ë¡œë“œ
    with st.spinner("ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘..."):
        model = load_model(model_path)
    
    # ì‚¬ì´ë“œë°” - ì´ë¯¸ì§€ ì—…ë¡œë“œ ë˜ëŠ” ìƒ˜í”Œ ì„ íƒ
    st.sidebar.title("ì…ë ¥ ì´ë¯¸ì§€ ì„ íƒ")
    input_option = st.sidebar.radio(
        "ì´ë¯¸ì§€ ì†ŒìŠ¤ ì„ íƒ:",
        ["ì´ë¯¸ì§€ ì—…ë¡œë“œ", "ìƒ˜í”Œ ì´ë¯¸ì§€ ì‚¬ìš©"]
    )
    
    # ë©”ì¸ ì˜ì—­
    col1, col2, col3 = st.columns(3)
    
    if input_option == "ì´ë¯¸ì§€ ì—…ë¡œë“œ":
        uploaded_file = st.sidebar.file_uploader("ì´ë¯¸ì§€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["jpg", "jpeg", "png"])
        
        if uploaded_file is not None:
            # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ë¡œë“œ
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            with st.spinner("ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘..."):
                # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                tensor_img, color_img, gray_img = preprocess_image(image)
                
                # ëª¨ë¸ ì˜ˆì¸¡
                with torch.no_grad():
                    output = model(tensor_img)
                
                # ì˜ˆì¸¡ ê²°ê³¼ í›„ì²˜ë¦¬
                pred_mask, restored_img = postprocess_prediction(output, color_img)
                
                # ê²°ê³¼ í‘œì‹œ
                with col1:
                    st.subheader("1. í‘ë°± ì…ë ¥ ì´ë¯¸ì§€")
                    st.image(gray_img, use_container_width=True)
                
                with col2:
                    st.subheader("2. ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼")
                    st.image(pred_mask, use_container_width=True)
                
                with col3:
                    st.subheader("3. ìƒ‰ìƒ ë³µì› ì´ë¯¸ì§€")
                    st.image(restored_img, use_container_width=True)
                
                # ì—¬ê¸°ì„œëŠ” ì‹¤ì œ ë§ˆìŠ¤í¬ê°€ ì—†ìœ¼ë¯€ë¡œ ì„ì˜ì˜ ë§ˆìŠ¤í¬ë¡œ ë©”íŠ¸ë¦­ ê³„ì‚°
                dummy_true_mask = np.zeros_like(gray_img)
                center_x, center_y = IMG_WIDTH // 2, IMG_HEIGHT // 2
                radius = min(IMG_WIDTH, IMG_HEIGHT) // 3
                cv2.circle(dummy_true_mask, (center_x, center_y), radius, 255, -1)
                
                metrics = calculate_metrics(dummy_true_mask, pred_mask)
                
                # ë©”íŠ¸ë¦­ í‘œì‹œ
                st.markdown("---")
                st.subheader("ğŸ” í‰ê°€ ì§€í‘œ")
                
                # ë©”íŠ¸ë¦­ ì°¨íŠ¸
                metric_chart = visualize_metrics(metrics)
                st.pyplot(metric_chart)
                
                # í…ìŠ¤íŠ¸ë¡œ ë©”íŠ¸ë¦­ í‘œì‹œ
                st.markdown("### ìƒì„¸ ìˆ˜ì¹˜")
                col_m1, col_m2 = st.columns(2)
                with col_m1:
                    st.info(f"IoU: {metrics['IoU']:.4f}")
                    st.info(f"Precision: {metrics['Precision']:.4f}")
                with col_m2:
                    st.info(f"Recall: {metrics['Recall']:.4f}")
                    st.info(f"F1 Score: {metrics['F1 Score']:.4f}")
    
    else:  # ìƒ˜í”Œ ì´ë¯¸ì§€ ì‚¬ìš©
        sample_images = get_sample_images(base_dir)
        
        if not sample_images:
            st.warning("ìƒ˜í”Œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ë””ë ‰í† ë¦¬ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return
            
        selected_sample = st.sidebar.selectbox(
            "ìƒ˜í”Œ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
            options=sample_images,
            format_func=lambda x: x["name"]
        )
        
        if selected_sample:
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            with st.spinner("ìƒ˜í”Œ ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘..."):
                # ìƒ˜í”Œ ì´ë¯¸ì§€ ë¡œë“œ
                color_img, true_mask = load_sample_image(selected_sample)
                
                # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                tensor_img, _, gray_img = preprocess_image(color_img)
                
                # ëª¨ë¸ ì˜ˆì¸¡
                with torch.no_grad():
                    output = model(tensor_img)
                
                # ì˜ˆì¸¡ ê²°ê³¼ í›„ì²˜ë¦¬
                pred_mask, restored_img = postprocess_prediction(output, color_img)
                
                # ê²°ê³¼ í‘œì‹œ
                with col1:
                    st.subheader("1. í‘ë°± ì…ë ¥ ì´ë¯¸ì§€")
                    st.image(gray_img, use_container_width=True)
                
                with col2:
                    st.subheader("2. ëª¨ë¸ ì˜ˆì¸¡ ê²°ê³¼")
                    st.image(pred_mask, use_container_width=True)
                
                with col3:
                    st.subheader("3. ìƒ‰ìƒ ë³µì› ì´ë¯¸ì§€")
                    st.image(restored_img, use_container_width=True)
                
                # ë©”íŠ¸ë¦­ ê³„ì‚°
                metrics = calculate_metrics(true_mask, pred_mask)
                
                # ë©”íŠ¸ë¦­ í‘œì‹œ
                st.markdown("---")
                st.subheader("ğŸ” í‰ê°€ ì§€í‘œ")
                
                # ë©”íŠ¸ë¦­ ì°¨íŠ¸
                metric_chart = visualize_metrics(metrics)
                st.pyplot(metric_chart)
                
                # í…ìŠ¤íŠ¸ë¡œ ë©”íŠ¸ë¦­ í‘œì‹œ
                st.markdown("### ìƒì„¸ ìˆ˜ì¹˜")
                col_m1, col_m2 = st.columns(2)
                with col_m1:
                    st.info(f"IoU: {metrics['IoU']:.4f}")
                    st.info(f"Precision: {metrics['Precision']:.4f}")
                with col_m2:
                    st.info(f"Recall: {metrics['Recall']:.4f}")
                    st.info(f"F1 Score: {metrics['F1 Score']:.4f}")
    
    # í˜ì´ì§€ í•˜ë‹¨ ì •ë³´
    st.markdown("---")
    st.markdown("### ëª¨ë¸ ì •ë³´")
    st.markdown("ì´ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ì€ U-Net with ResNet50 ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    st.markdown("ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ì€ ì´ë¯¸ì§€ì—ì„œ ì¤‘ìš”í•œ ì˜ì—­ì„ ë¶„ë¦¬í•˜ê³ , ê·¸ ì˜ì—­ì— ëŒ€í•´ ì›ë³¸ ìƒ‰ìƒì„ ë³µì›í•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    main()