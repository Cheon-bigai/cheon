# 🐦 새 종류 이미지 분류 프로젝트

전통적인 머신러닝 기법을 활용한 새 종류 이미지 분류 프로젝트입니다. 이 프로젝트는 딥러닝 모델이 주류인 현대 컴퓨터 비전 환경에서도 전통적인 머신러닝 접근법의 가치를 재평가하기 위해 수행되었습니다.

## 📋 프로젝트 개요

- **목적**: 전통적인 머신러닝 기법을 사용하여 새 종류 이미지 분류 모델 개발
- **데이터셋**: 25개 종류의 새 이미지 (훈련 4,500장, 테스트 500장)
- **이미지 해상도**: 64x64 픽셀 (훈련), 256x256 픽셀 (고해상도 훈련)

## 🔍 전통적인 머신러닝 vs. 딥러닝

### 특징 추출 (Feature Extraction)

**전통적인 머신러닝**:
- 수동 특징 추출: SIFT, HOG, SURF, Haar-like 특징 등
- 도메인 지식 필요: 중요한 특징에 대한 사전 지식 필요
- 파이프라인: 특징 추출 → 특징 선택 → 분류기 학습의 단계적 접근

**딥러닝**:
- 자동 특징 학습: 네트워크가 원시 픽셀 데이터로부터 자동으로 특징 학습
- 계층적 특징 표현: 저수준 특징에서 고수준 특징까지 자동 학습
- 종단간(End-to-End) 학습: 특징 추출과 분류가 하나의 네트워크로 통합

### 모델 복잡성

**전통적인 머신러닝**:
- 비교적 단순한 모델: SVM, 랜덤 포레스트, k-NN 등
- 파라미터 수: 수천~수만 정도
- 해석 가능성: 상대적으로 모델 해석이 용이함

**딥러닝**:
- 복잡한 다층 아키텍처: CNN, ResNet, EfficientNet 등
- 파라미터 수: 수백만~수억 파라미터
- 블랙박스 특성: 모델의 결정 과정 해석이 어려움

### 데이터 요구사항

**전통적인 머신러닝**:
- 데이터 요구량: 수백~수천 개 이미지로도 좋은 성능 가능
- 전처리 의존도: 강한 전처리 필요
- 차원 감소: PCA, t-SNE 등 차원 축소 활용

**딥러닝**:
- 대량 데이터 요구: 일반적으로 수만~수백만 이미지 필요
- 최소한의 전처리로 활용 가능
- 데이터 증강 중요

## 🛠️ 프로젝트 구현

### 데이터 전처리

1. **바운딩 박스 설정**: 새를 이미지 중앙에 위치시켜 배경 영향 최소화
2. **이미지 크기 정규화**: 모든 이미지를 64x64 픽셀로 통일
3. **그레이스케일 변환**: HOG 특징 추출을 위한 전처리

### 특징 추출

1. **HSV 히스토그램**
   - 색상(Hue), 채도(Saturation), 명도(Value) 히스토그램 추출
   - 새 종류의 독특한 색상 패턴 포착

2. **HOG(Histogram of Oriented Gradients)**
   - 이미지의 지역적 그래디언트 방향 분포 특징화
   - 새의 실루엣, 부리 모양, 날개 패턴 등 구조적 특징 포착
   - 형태 특징 포착에 강점
   - 회전과 크기 변화에 일정 수준의 불변성
   - 과적합 위험 감소

### 모델링

1. **SVM(Support Vector Machine)**
   - 고차원 특징 공간에서 클래스 분리
   - 비선형 커널을 통한 복잡한 결정 경계 학습
   - 희소한 데이터셋에서 견고성 유지

2. **Random Forest**
   - 여러 결정 트리의 예측 결합
   - 특징 중요도 파악 용이
   - 과적합에 강한 내성
   - 이상치에 대한 견고성

3. **KNN(K-Nearest Neighbors)**
   - 새로운 데이터 포인트의 클래스를 가장 가까운 K개 이웃의 다수결로 결정
   - 간단하지만 효과적인 알고리즘
   - 복잡한 결정 경계 학습 가능

4. **앙상블 모델**
   - 다양한 모델의 장점을 결합한 투표 기반 앙상블
   - 개선된 예측 성능
   - 과적합 위험 감소
   - 더 안정적이고 견고한 예측

## 📊 결과 분석

### 모델 성능

- **SVM**: 21.91% 오차율
- **Random Forest**: 18.38% 오차율
- **KNN**: 16.04% 오차율
- **앙상블 모델**: 24.63% 오차율 (최고 성능)

### 오차 분석

1. **혼동 행렬 분석**
   - 일부 클래스 쌍은 서로 자주 혼동됨 (예: Jungle Babbler와 Common Rosefinch)
   - 가장 높은 정확도를 보인 클래스: Asian Green Bee-Eater (51%)

2. **문제 클래스 분석**
   - Forest Wagtail 클래스는 정확하게 분류하는 데 가장 큰 어려움
   - Forest Wagtail과 Gray Wagtail 간의 혼동 비율이 높음 (시각적 유사성)

3. **샘플 수와 오차율의 관계**
   - 샘플 수와 오차율 사이에 약한 음의 상관관계 (r = -0.23)
   - 데이터가 더 많을수록 오차율이 감소하는 경향
   - 데이터 증가만으로는 모든 클래스의 성능 향상에 한계

## 🔑 결론

1. **데이터 양의 중요성**
   - 데이터 증가에 따른 성능 향상 확인
   - 희소한 클래스에 대한 데이터 수집의 중요성

2. **전처리의 중요성**
   - 세밀한 분류 작업에서는 도메인 지식을 활용한 전처리가 성능에 큰 영향
   - 바운딩 박스 설정, 이미지 정규화, 적절한 특징 추출이 핵심

3. **앙상블 접근법의 효과**
   - 단일 모델보다 앙상블 모델의 성능이 우수
   - 각 모델의 장점을 결합하는 효과 입증

## 🔮 향후 개선 방향

1. **특징 추출 향상**
   - HSV 히스토그램과 HOG 외에도 LBP, SIFT 등 추가 특징 추출 기법 도입
   - 하이브리드 접근법: 전통적 머신러닝과 딥러닝의 장점 결합

2. **데이터 보강**
   - 클래스 불균형 해결을 위한 데이터 증강 기법 적용
   - 희소한 클래스의 샘플 수 증가

3. **하이퍼파라미터 최적화**
   - 그리드 서치나 베이지안 최적화를 통한 모델 파라미터 튜닝

4. **전처리 개선**
   - 새의 위치 자동 감지 알고리즘 개선
   - 이미지 중앙 가정에서 벗어난 객체 탐지 강화

## 🔄 실행 방법

1. 필요한 라이브러리 설치
```
pip install numpy pandas opencv-python matplotlib scikit-learn scikit-image seaborn tqdm joblib koreanize-matplotlib
```

2. 데이터셋 구조 준비
```
data/
├── train/           # 64x64 픽셀 훈련 이미지
├── upscale_train/   # 256x256 픽셀 훈련 이미지
├── test/            # 테스트 이미지
├── train.csv        # 훈련 데이터 메타데이터
└── test.csv         # 테스트 데이터 메타데이터
```

3. 코드 실행
```python
python 새를_주제로_이미지를_분류해보자.py
```

## 📝 프로젝트 회고

전통적인 머신러닝 방법을 사용한 이미지 분류는 여전히 가치가 있습니다. 특히 다음과 같은 장점이 있습니다:

- 적은 데이터로도 합리적인 성능 달성
- 해석 가능성과 명확한 특징 중요도 파악
- 계산 자원 효율성

그러나 다음과 같은 한계도 존재합니다:

- 수동으로 설계된 특징의 한계
- 특징 계층화 부재
- 도메인 지식 의존성
- 공간적 관계 이해 부족

이 프로젝트는 전통적인 머신러닝과 현대 딥러닝 접근법의 상호 보완적 관계를 보여주며, 문제와 자원에 따라 적절한 방법론 선택의 중요성을 강조합니다.
